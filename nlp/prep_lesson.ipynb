{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prep_lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rachelreuter/ds-methodologies/nlp/acquire.py:19: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 19 of the file /Users/rachelreuter/ds-methodologies/nlp/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "links = ['https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/',\n",
    "         'https://codeup.com/why-san-antonio-has-more-than-tacos-to-offer/',\n",
    "         'https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "         'https://codeup.com/data-science-myths/',\n",
    "         'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/'\n",
    "        ]\n",
    "\n",
    "def get_blog_articles(url):\n",
    "    headers = {'User-Agent': 'Codeup Ada Data Science'}\n",
    "    response = get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    title = soup.find('title')\n",
    "    content = soup.find('div', class_='mk-single-content')\n",
    "\n",
    "    d = dict()\n",
    "    d['title'] = title.text\n",
    "    d['content'] = content.text\n",
    "    return d\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for link in links:\n",
    "    corpus.append((get_blog_articles(link)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = corpus[2]['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above creates an \"original\" copy that we'll pull in later, down below.  Save it here for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a working \"article\" copy of the original, that we'll perform all the transformations to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in Glassdoor’s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio, resulting in an explosion in Data Scientist positions across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen UTSA invest $70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in 14 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\n",
      "Applications are now open for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = article.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoor’s #1 best job in america. data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. we’ve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry. our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce. we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we’re focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development. applications are now open for codeup’s first data science cohort, which will start class on february 4, 2019. hurry – there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio. if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com! \n"
     ]
    }
   ],
   "source": [
    "print(re.sub(r'\\s', ' ',article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing accented characters\n",
    "In 3 steps:\n",
    "\n",
    "NORMALIZING (unicodedata.normalize removes any inconsistenceies in unicode character encoding)\n",
    "\n",
    "ENCODING, and (.encode to convert resulting string into the ascii character set.  Use \"ignore\"  for any conversion errors, meaning we'll drop anything that's not an ascii character.)\n",
    "\n",
    "DECODING (.decode to turn resulting Python Bytes object back into a string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing, encoding, decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized = unicodedata.normalize('NFKD', article).encode('ascii','ignore').decode('utf-8','ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoors #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. weve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program. were focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning  regression; 6) supervised machine learning  classification; 7) unsupervised machine learning  clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeups first data science cohort, which will start class on february 4, 2019. hurry  there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now store it back into the original \"article\" name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoors #1 best job in america.\\ndata science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. weve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\\nour program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nwe focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program. were focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning  regression; 6) supervised machine learning  classification; 7) unsupervised machine learning  clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\\napplications are now open for codeups first data science cohort, which will start class on february 4, 2019. hurry  there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\\nif you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = re.sub(r\"[^a-z0-9\\s]\", '', article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "the rumors are true the time has arrived codeup has officially opened applications to our new data science career accelerator with only 25 seats available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america\n",
      "data science is a method of providing actionable intelligence from data the data revolution has hit san antonio resulting in an explosion in data scientist positions across companies like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demands of this industry\n",
      "our program will be 18 weeks long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who has worked at heb capital group and rackspace along with input from dozens of practitioners and hiring partners students will work with real data sets realistic problems and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce\n",
      "we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program were focusing on data science with python sql and ml covered in 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning  regression 6 supervised machine learning  classification 7 unsupervised machine learning  clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development\n",
      "applications are now open for codeups first data science cohort which will start class on february 4 2019 hurry  there are only 25 seats available to further our mission of cultivating inclusive growth scholarships will be available to women minorities lgbtqia individuals veterans first responders and people relocating to san antonio\n",
      "if you want to learn about joining our program or hiring our graduates email datasciencecodeupcom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "The process we've just gone through, that is, removing non-ascii characters and special characters can be thought of as a kind of tokenization.\n",
    "\n",
    "Tokenization is the process of breaking something down into discrete units. In the context of NLP, this means breaking text down into discrete words, punctuation, etc.\n",
    "\n",
    "This breaks the text down into discete units, separating punctuation from words.\n",
    "\n",
    "We can also use nltk to do tokenization for us:\n",
    "\n",
    "Use redex for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# \"natural language took kit\"\n",
    "# this handles all sorts of word and language stuffs.\n",
    "# it may require a list of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the thing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rumors are true ! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator , with only 25 seats available ! This immersive program is one of a kind in San Antonio , and will help you land a job in Glassdoor ’ s #1 Best Job in America.\n",
      "Data Science is a method of providing actionable intelligence from data. The data revolution has hit San Antonio , resulting in an explosion in Data Scientist positions across companies like USAA , Accenture , Booz Allen Hamilton , and HEB. We ’ ve even seen UTSA invest $ 70 M for a Cybersecurity Center and School of Data Science. We built a program to specifically meet the growing demands of this industry.\n",
      "Our program will be 18 weeks long , full-time , hands-on , and project-based. Our curriculum development and instruction is led by Senior Data Scientist , Maggie Giust , who has worked at HEB , Capital Group , and Rackspace , along with input from dozens of practitioners and hiring partners. Students will work with real data sets , realistic problems , and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing , interviewing , and continuing education to prepare for a smooth transition to the workforce.\n",
      "We focus on applied data science for immediate impact and ROI in a business , which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We ’ re focusing on Data Science with Python , SQL , and ML , covered in 14 modules : 1 ) Fundamentals ; 2 ) Applied statistics ; 3 ) SQL ; 4 ) Python ; 5 ) Supervised machine learning – regression ; 6 ) Supervised machine learning – classification ; 7 ) Unsupervised machine learning – clustering ; 8 ) Time series analysis ; 9 ) Anomaly detection ; 10 ) Natural language processing ; 11 ) Distributed machine learning ; 12 ) Advanced topics ( deep learning , NoSQL , cloud deployment , etc. ) ; 13 ) Storytelling with data ; and 14 ) Domain expertise development.\n",
      "Applications are now open for Codeup ’ s first Data Science cohort , which will start class on February 4 , 2019. Hurry – there are only 25 seats available ! To further our mission of cultivating inclusive growth , scholarships will be available to women , minorities , LGBTQIA+ individuals , veterans , first responders , and people relocating to San Antonio.\n",
      "If you want to learn about joining our program or hiring our graduates , email datascience@codeup.com !\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(original, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization\n",
    "Usually you will want to use lemmatization, but we'll look at both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below here is Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the nltk stemmer object, then use it\n",
    "ps = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('call', 'call', 'call')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('calls'), ps.stem('called'), ps.stem('calling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call', 'call', 'call']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ps.stem(word) for word in ['call','called','calling']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply this stemming transformation to all the words in the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stems = [ps.stem(word) for word in article.split()]\n",
    "article_stemmed = ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumor are true the time ha arriv codeup ha offici open applic to our new data scienc career acceler with onli 25 seat avail thi immers program is one of a kind in san antonio and will help you land a job in glassdoor 1 best job in america data scienc is a method of provid action intellig from data the data revolut ha hit san antonio result in an explos in data scientist posit across compani like usaa accentur booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecur center and school of data scienc we built a program to specif meet the grow demand of thi industri our program will be 18 week long fulltim handson and projectbas our curriculum develop and instruct is led by senior data scientist maggi giust who ha work at heb capit group and rackspac along with input from dozen of practition and hire partner student will work with real data set realist problem and the entir data scienc pipelin from collect to deploy they will receiv profession develop train in resum write interview and continu educ to prepar for a smooth transit to the workforc we focu on appli data scienc for immedi impact and roi in a busi which is how we can back it all up with a 6 month tuition refund guarante just like our exist web dev program were focus on data scienc with python sql and ml cover in 14 modul 1 fundament 2 appli statist 3 sql 4 python 5 supervis machin learn regress 6 supervis machin learn classif 7 unsupervis machin learn cluster 8 time seri analysi 9 anomali detect 10 natur languag process 11 distribut machin learn 12 advanc topic deep learn nosql cloud deploy etc 13 storytel with data and 14 domain expertis develop applic are now open for codeup first data scienc cohort which will start class on februari 4 2019 hurri there are onli 25 seat avail to further our mission of cultiv inclus growth scholarship will be avail to women minor lgbtqia individu veteran first respond and peopl reloc to san antonio if you want to learn about join our program or hire our graduat email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "print(article_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is how to do this in steps.  Below is a list comprehension to make it more streamlined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(' '.join([ps.stem(word) for word in article.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data      13\n",
       "and       13\n",
       "to         9\n",
       "a          8\n",
       "in         8\n",
       "scienc     7\n",
       "our        7\n",
       "learn      6\n",
       "the        6\n",
       "with       6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(stems).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, below here is Lemmatization, which we'll be using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is very similar to stemming, however, the base form in this case is known as the root word, but not the root stem. The difference is that the root word is always a lexicographically correct word (present in the dictionary), but the root stem may not be so. Thus, root word, also known as the lemma, will always be present in the dictionary.\n",
    "\n",
    "Note that the lemmatization process is considerably slower than stemming, because an additional step is involved where the root form or lemma is formed by removing the affix from the word if and only if the lemma is present in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rachelreuter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stem: studi -- lemma: study\n",
      "stem: studi -- lemma: study\n"
     ]
    }
   ],
   "source": [
    "for word in 'study studies'.split():\n",
    "    print('stem:', ps.stem(word), '-- lemma:', wnl.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply lemmatization to the entire document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [wnl.lemmatize(word.lower()) for word in article.split()]\n",
    "article_lemmatized = ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumor are true the time ha arrived codeup ha officially opened application to our new data science career accelerator with only 25 seat available this immersive program is one of a kind in san antonio and will help you land a job in glassdoors 1 best job in america data science is a method of providing actionable intelligence from data the data revolution ha hit san antonio resulting in an explosion in data scientist position across company like usaa accenture booz allen hamilton and heb weve even seen utsa invest 70 m for a cybersecurity center and school of data science we built a program to specifically meet the growing demand of this industry our program will be 18 week long fulltime handson and projectbased our curriculum development and instruction is led by senior data scientist maggie giust who ha worked at heb capital group and rackspace along with input from dozen of practitioner and hiring partner student will work with real data set realistic problem and the entire data science pipeline from collection to deployment they will receive professional development training in resume writing interviewing and continuing education to prepare for a smooth transition to the workforce we focus on applied data science for immediate impact and roi in a business which is how we can back it all up with a 6 month tuition refund guarantee just like our existing web dev program were focusing on data science with python sql and ml covered in 14 module 1 fundamental 2 applied statistic 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topic deep learning nosql cloud deployment etc 13 storytelling with data and 14 domain expertise development application are now open for codeups first data science cohort which will start class on february 4 2019 hurry there are only 25 seat available to further our mission of cultivating inclusive growth scholarship will be available to woman minority lgbtqia individual veteran first responder and people relocating to san antonio if you want to learn about joining our program or hiring our graduate email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "print(article_lemmatized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a list of the lemmas, or actual root words, we can look at the most frequent words.\n",
    "\n",
    "It generates the 'bag of words' we spoke of earlier, with a list of words and their respective counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data       13\n",
       "and        13\n",
       "to          9\n",
       "in          8\n",
       "a           8\n",
       "science     7\n",
       "our         7\n",
       "will        6\n",
       "of          6\n",
       "the         6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lemmas).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words which have little or no significance, especially when constructing meaningful features from text, are known as stop words (or stopwords). These are usually words that end up having the maximum frequency if you do a simple term or word frequency in a corpus. Typically, these can be articles, conjunctions, prepositions and so on. Some examples of stopwords are a, an, the, and like.\n",
    "\n",
    "While there is no universal stopword list, we will use a standard English language stopwords list from nltk. You can also add your own domain-specific stopwords as needed.\n",
    "\n",
    "Before removing stopwords, we want to segment text into linguistic units such as words or numbers. This process is called tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without_stopwords = [word for word in lemmas if word not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = article.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rumors',\n",
       " 'true',\n",
       " 'time',\n",
       " 'arrived',\n",
       " 'codeup',\n",
       " 'officially',\n",
       " 'opened',\n",
       " 'applications',\n",
       " 'new',\n",
       " 'data',\n",
       " 'science',\n",
       " 'career',\n",
       " 'accelerator',\n",
       " '25',\n",
       " 'seats',\n",
       " 'available',\n",
       " 'immersive',\n",
       " 'program',\n",
       " 'one',\n",
       " 'kind',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'help',\n",
       " 'land',\n",
       " 'job',\n",
       " 'glassdoors',\n",
       " '1',\n",
       " 'best',\n",
       " 'job',\n",
       " 'america',\n",
       " 'data',\n",
       " 'science',\n",
       " 'method',\n",
       " 'providing',\n",
       " 'actionable',\n",
       " 'intelligence',\n",
       " 'data',\n",
       " 'data',\n",
       " 'revolution',\n",
       " 'hit',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'resulting',\n",
       " 'explosion',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'positions',\n",
       " 'across',\n",
       " 'companies',\n",
       " 'like',\n",
       " 'usaa',\n",
       " 'accenture',\n",
       " 'booz',\n",
       " 'allen',\n",
       " 'hamilton',\n",
       " 'heb',\n",
       " 'weve',\n",
       " 'even',\n",
       " 'seen',\n",
       " 'utsa',\n",
       " 'invest',\n",
       " '70',\n",
       " 'cybersecurity',\n",
       " 'center',\n",
       " 'school',\n",
       " 'data',\n",
       " 'science',\n",
       " 'built',\n",
       " 'program',\n",
       " 'specifically',\n",
       " 'meet',\n",
       " 'growing',\n",
       " 'demands',\n",
       " 'industry',\n",
       " 'program',\n",
       " '18',\n",
       " 'weeks',\n",
       " 'long',\n",
       " 'fulltime',\n",
       " 'handson',\n",
       " 'projectbased',\n",
       " 'curriculum',\n",
       " 'development',\n",
       " 'instruction',\n",
       " 'led',\n",
       " 'senior',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'maggie',\n",
       " 'giust',\n",
       " 'worked',\n",
       " 'heb',\n",
       " 'capital',\n",
       " 'group',\n",
       " 'rackspace',\n",
       " 'along',\n",
       " 'input',\n",
       " 'dozens',\n",
       " 'practitioners',\n",
       " 'hiring',\n",
       " 'partners',\n",
       " 'students',\n",
       " 'work',\n",
       " 'real',\n",
       " 'data',\n",
       " 'sets',\n",
       " 'realistic',\n",
       " 'problems',\n",
       " 'entire',\n",
       " 'data',\n",
       " 'science',\n",
       " 'pipeline',\n",
       " 'collection',\n",
       " 'deployment',\n",
       " 'receive',\n",
       " 'professional',\n",
       " 'development',\n",
       " 'training',\n",
       " 'resume',\n",
       " 'writing',\n",
       " 'interviewing',\n",
       " 'continuing',\n",
       " 'education',\n",
       " 'prepare',\n",
       " 'smooth',\n",
       " 'transition',\n",
       " 'workforce',\n",
       " 'focus',\n",
       " 'applied',\n",
       " 'data',\n",
       " 'science',\n",
       " 'immediate',\n",
       " 'impact',\n",
       " 'roi',\n",
       " 'business',\n",
       " 'back',\n",
       " '6',\n",
       " 'month',\n",
       " 'tuition',\n",
       " 'refund',\n",
       " 'guarantee',\n",
       " 'like',\n",
       " 'existing',\n",
       " 'web',\n",
       " 'dev',\n",
       " 'program',\n",
       " 'focusing',\n",
       " 'data',\n",
       " 'science',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'ml',\n",
       " 'covered',\n",
       " '14',\n",
       " 'modules',\n",
       " '1',\n",
       " 'fundamentals',\n",
       " '2',\n",
       " 'applied',\n",
       " 'statistics',\n",
       " '3',\n",
       " 'sql',\n",
       " '4',\n",
       " 'python',\n",
       " '5',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'regression',\n",
       " '6',\n",
       " 'supervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'classification',\n",
       " '7',\n",
       " 'unsupervised',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'clustering',\n",
       " '8',\n",
       " 'time',\n",
       " 'series',\n",
       " 'analysis',\n",
       " '9',\n",
       " 'anomaly',\n",
       " 'detection',\n",
       " '10',\n",
       " 'natural',\n",
       " 'language',\n",
       " 'processing',\n",
       " '11',\n",
       " 'distributed',\n",
       " 'machine',\n",
       " 'learning',\n",
       " '12',\n",
       " 'advanced',\n",
       " 'topics',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'nosql',\n",
       " 'cloud',\n",
       " 'deployment',\n",
       " 'etc',\n",
       " '13',\n",
       " 'storytelling',\n",
       " 'data',\n",
       " '14',\n",
       " 'domain',\n",
       " 'expertise',\n",
       " 'development',\n",
       " 'applications',\n",
       " 'open',\n",
       " 'codeups',\n",
       " 'first',\n",
       " 'data',\n",
       " 'science',\n",
       " 'cohort',\n",
       " 'start',\n",
       " 'class',\n",
       " 'february',\n",
       " '4',\n",
       " '2019',\n",
       " 'hurry',\n",
       " '25',\n",
       " 'seats',\n",
       " 'available',\n",
       " 'mission',\n",
       " 'cultivating',\n",
       " 'inclusive',\n",
       " 'growth',\n",
       " 'scholarships',\n",
       " 'available',\n",
       " 'women',\n",
       " 'minorities',\n",
       " 'lgbtqia',\n",
       " 'individuals',\n",
       " 'veterans',\n",
       " 'first',\n",
       " 'responders',\n",
       " 'people',\n",
       " 'relocating',\n",
       " 'san',\n",
       " 'antonio',\n",
       " 'want',\n",
       " 'learn',\n",
       " 'joining',\n",
       " 'program',\n",
       " 'hiring',\n",
       " 'graduates',\n",
       " 'email',\n",
       " 'datasciencecodeupcom']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 122 stopwords\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_without_stopwords = ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumors true time arrived codeup officially opened applications new data science career accelerator 25 seats available immersive program one kind san antonio help land job glassdoors 1 best job america data science method providing actionable intelligence data data revolution hit san antonio resulting explosion data scientist positions across companies like usaa accenture booz allen hamilton heb weve even seen utsa invest 70 cybersecurity center school data science built program specifically meet growing demands industry program 18 weeks long fulltime handson projectbased curriculum development instruction led senior data scientist maggie giust worked heb capital group rackspace along input dozens practitioners hiring partners students work real data sets realistic problems entire data science pipeline collection deployment receive professional development training resume writing interviewing continuing education prepare smooth transition workforce focus applied data science immediate impact roi business back 6 month tuition refund guarantee like existing web dev program focusing data science python sql ml covered 14 modules 1 fundamentals 2 applied statistics 3 sql 4 python 5 supervised machine learning regression 6 supervised machine learning classification 7 unsupervised machine learning clustering 8 time series analysis 9 anomaly detection 10 natural language processing 11 distributed machine learning 12 advanced topics deep learning nosql cloud deployment etc 13 storytelling data 14 domain expertise development applications open codeups first data science cohort start class february 4 2019 hurry 25 seats available mission cultivating inclusive growth scholarships available women minorities lgbtqia individuals veterans first responders people relocating san antonio want learn joining program hiring graduates email datasciencecodeupcom\n"
     ]
    }
   ],
   "source": [
    "print(article_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
